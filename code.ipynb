{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "728d1cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models, regularizers, activations, callbacks, optimizers, backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import models, layers, regularizers, callbacks, optimizers\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Add, Concatenate\n",
    "import shap\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b67af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows: 10050\n",
      "Rows removed due to NA: 110\n",
      "Rows removed due to logical constraints: 0\n",
      "Rows removed as duplicates: 50\n",
      "\n",
      "Column: Tank Failure Pressure\n",
      "  IQR range: [-16.27, 62.29]\n",
      "  Count of outliers: 48\n",
      "  Sample outlier values:\n",
      "1446.628788\n",
      "3404.750305\n",
      "1722.348566\n",
      "4095.753928\n",
      "2379.656661\n",
      "\n",
      "Column: Vapour Height\n",
      "  IQR range: [-0.79, 2.41]\n",
      "  Count of outliers: 38\n",
      "  Sample outlier values:\n",
      "2.60\n",
      "2.59\n",
      "2.59\n",
      "2.61\n",
      "2.60\n",
      "\n",
      "Column: Sensor Position y\n",
      "  IQR range: [-9.47, 15.53]\n",
      "  Count of outliers: 33\n",
      "  Sample outlier values:\n",
      "16.2\n",
      "16.2\n",
      "16.2\n",
      "16.2\n",
      "16.2\n",
      "\n",
      "Column: Sensor Position z\n",
      "  IQR range: [-9.90, 14.90]\n",
      "  Count of outliers: 33\n",
      "  Sample outlier values:\n",
      "15.7\n",
      "15.7\n",
      "15.7\n",
      "15.7\n",
      "15.7\n",
      "\n",
      "Column: Target Pressure\n",
      "  IQR range: [-0.36, 0.88]\n",
      "  Count of outliers: 882\n",
      "  Sample outlier values:\n",
      "1.093819\n",
      "1.091484\n",
      "1.036741\n",
      "1.163416\n",
      "1.136221\n",
      "\n",
      "Total outliers removed: 1034\n",
      "Rows removed as outliers: 1034\n",
      "Final rows: 8856\n",
      "Total rows removed: 1194\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers_iqr(df, numeric_cols):\n",
    "    cleaned_df = df.copy()\n",
    "    total_outliers = 0\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        Q1 = cleaned_df[col].quantile(0.25)\n",
    "        Q3 = cleaned_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = cleaned_df[(cleaned_df[col] < lower_bound) | (cleaned_df[col] > upper_bound)]\n",
    "        cleaned_df = cleaned_df[(cleaned_df[col] >= lower_bound) & (cleaned_df[col] <= upper_bound)]\n",
    "\n",
    "        outlier_count = len(outliers)\n",
    "        if outlier_count > 0:\n",
    "            print(f\"\\nColumn: {col}\")\n",
    "            print(f\"  IQR range: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "            print(f\"  Count of outliers: {outlier_count}\")\n",
    "            print(f\"  Sample outlier values:\\n{outliers[col].head(5).to_string(index=False)}\")\n",
    "\n",
    "        total_outliers += outlier_count\n",
    "\n",
    "    print(f\"\\nTotal outliers removed: {total_outliers}\")\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_engineer(data):\n",
    "    \n",
    "    data[\"Liquid Boiling Temperature\"] = data[\"Liquid Boiling Temperature\"] +273.15\n",
    "    data[\"Liquid Critical Temperature\"] = data[\"Liquid Critical Temperature\"] +273.15\n",
    "    data[\"Tank Volume\"] = data[\"Tank Width\"] * data[\"Tank Length\"] * data[\"Tank Height\"]  \n",
    "    data[\"HeightRatio\"]= data[\"Vapour Height\"] / data[\"Tank Height\"] \n",
    "    data[\"Superheat Margin\"] = data[\"Liquid Temperature\"] - data[\"Liquid Boiling Temperature\"]\n",
    "    # Total Energy (approximate thermal energy in the tank)\n",
    "    data[\"Liquid Volume\"] = data[\"Liquid Ratio\"] * data[\"Tank Volume\"]\n",
    "    data[\"Total Energy\"] = data[\"Liquid Volume\"] * data[\"Superheat Margin\"]\n",
    "\n",
    "    # (BLEVE assumed at tank center top)\n",
    "    data[\"Sensor Distance to BLEVE\"] = (\n",
    "        data[\"Sensor Position x\"]**2 +\n",
    "        data[\"Sensor Position y\"]**2 +\n",
    "        (data[\"Sensor Position z\"] - data[\"BLEVE Height\"])**2\n",
    "    ) ** 0.5\n",
    "    data = pd.get_dummies(data, columns=[\"Sensor Position Side\"], prefix=\"Side\")\n",
    "    data = pd.get_dummies(data, columns=[\"Status\"], prefix=\"Status\")\n",
    "    return data\n",
    "\n",
    "def cleanColumns(columns):\n",
    "    return [re.sub(r'\\s*\\([^)]*\\)', '', col).strip() for col in columns]\n",
    "\n",
    "def applyConstraints(data):\n",
    "    return data[(data['Tank Width'] > 0) & \n",
    "                (data['Tank Length'] > 0) & \n",
    "                (data['Tank Height'] > 0) & \n",
    "                (data['Vapour Height'] >= 0) &\n",
    "                (data['Vapour Temperature'] > 0) &\n",
    "                (data['Liquid Temperature'] > 0)]\n",
    "\n",
    "def handleMisspelling(data):\n",
    "    data[\"Status\"] = data[\"Status\"].str.lower().str.replace(' ', '')\n",
    "    data['Status'] = data['Status'].apply(lambda x: 'superheated' if 'h' in x else ('subcooled' if 'c' in x else x))\n",
    "    return data[\"Status\"]\n",
    "\n",
    "\n",
    "\n",
    "def remove_highly_correlated_features(df, threshold=0.9):\n",
    "    corr_matrix = df.corr(numeric_only=True).abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    \n",
    "    print(\"Highly correlated features to drop:\", to_drop)\n",
    "    return df.drop(columns=to_drop)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(data,test_dataset=False,feature_eng = True):\n",
    "    # Initial row count\n",
    "    initial_rows = len(data)\n",
    "    print(f\"Initial rows: {initial_rows}\")\n",
    "\n",
    "    # Clean column names\n",
    "    data.columns = cleanColumns(data.columns)\n",
    "\n",
    "    # Drop 'Unnamed: 0' column\n",
    "    if \"Unnamed: 0\" in data.columns:\n",
    "        data = data.drop([\"Unnamed: 0\"], axis=\"columns\")\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    before_na = len(data)\n",
    "    data = data.dropna(axis=0)\n",
    "    after_na = len(data)\n",
    "    print(f\"Rows removed due to NA: {before_na - after_na}\")\n",
    "\n",
    "    # Logical constraints\n",
    "    before_constraints = len(data)\n",
    "    data = applyConstraints(data)\n",
    "    after_constraints = len(data)\n",
    "    print(f\"Rows removed due to logical constraints: {before_constraints - after_constraints}\")\n",
    "\n",
    "    # Drop duplicates (if not test dataset)\n",
    "    if not test_dataset:\n",
    "        before_duplicates = len(data)\n",
    "        data = data.drop_duplicates()\n",
    "        after_duplicates = len(data)\n",
    "        print(f\"Rows removed as duplicates: {before_duplicates - after_duplicates}\")\n",
    "\n",
    "    # Standardize 'Status' column\n",
    "    data[\"Status\"] = handleMisspelling(data)\n",
    "\n",
    "    # Remove outliers (if not test dataset)\n",
    "    if not test_dataset:\n",
    "        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        before_outliers = len(data)\n",
    "        data = remove_outliers_iqr(data, numeric_cols)\n",
    "        after_outliers = len(data)\n",
    "        print(f\"Rows removed as outliers: {before_outliers - after_outliers}\")\n",
    "\n",
    "    # Final row count\n",
    "    final_rows = len(data)\n",
    "    print(f\"Final rows: {final_rows}\")\n",
    "    print(f\"Total rows removed: {initial_rows - final_rows}\")\n",
    "    data = pd.get_dummies(data, columns=[\"Sensor Position Side\"], prefix=\"Side\")\n",
    "    data = pd.get_dummies(data, columns=[\"Status\"], prefix=\"Status\")\n",
    "\n",
    "    y =  None\n",
    "    if (not test_dataset):\n",
    "        y= data[ \"Target Pressure\"] \n",
    "        data = data.drop([\"Target Pressure\"], axis=\"columns\")\n",
    "    \n",
    "    # StandardScaler for inputs\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_scaled = scaler.fit_transform(data)\n",
    "    return X_scaled,y\n",
    "\n",
    "\n",
    "\n",
    "def load_data(csvFileName):\n",
    "    data = pd.read_csv(csvFileName)\n",
    "    X_scaled,y = preprocess(data);\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    # print(\"Training Set Size:\", X_train.shape)\n",
    "    # print(\"Validation Set Size:\", X_val.shape)\n",
    "    return  X_train, X_val, y_train, y_val\n",
    "\n",
    "X_train, X_val, y_train, y_val = load_data(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1dc4de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "12 fits failed out of a total of 96.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:49] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x742c428a6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x742c43184c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x742c42b649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x742c427b3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x742c6443c052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x742c6443a925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x742c6443b06e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x742c6444cc88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x742c6444bc44]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:49] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x71f274ea6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x71f275784c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x71f2751649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x71f274db3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x71f2969a6052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x71f2969a4925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x71f2969a506e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x71f2969b6c88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x71f2969b5c44]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:48] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x711b1d6a6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x711b1df84c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x711b1d9649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x711b1d5b3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x711b3f197052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x711b3f195925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x711b3f19606e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x711b3f1a7c88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x711b3f1a6c44]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:48] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x7a278eea6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x7a278f784c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x7a278f1649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x7a278edb3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x7a27b09ce052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x7a27b09cc925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7a27b09cd06e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x7a27b09dec88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x7a27b09ddc44]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:48] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x7fe20eaa6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x7fe20f384c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x7fe20ed649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x7fe20e9b3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x7fe23062a052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x7fe230628925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7fe23062906e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x7fe23063ac88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x7fe230639c44]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:48] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x7bb2de4a6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x7bb2ded84c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x7bb2de7649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x7bb2de3b3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x7bb300026052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x7bb300024925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7bb30002506e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x7bb300036c88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x7bb300035c44]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:48] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x72d8044a6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x72d804d84c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x72d8047649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x72d8043b3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x72d82606e052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x72d82606c925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x72d82606d06e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x72d82607ec88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x72d82607dc44]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:48] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x7392a22a6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x7392a2b84c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x7392a25649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x7392a21b3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x7392c3d4e052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x7392c3d4c925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7392c3d4d06e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x7392c3d5ec88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x7392c3d5dc44]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:49] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 46) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x7b8d45aa6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x7b8d46384c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x7b8d45d649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x7b8d459b3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x7b8d675f3052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x7b8d675f1925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7b8d675f206e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x7b8d67603c88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x7b8d67602c44]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:48] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x7479e2aa6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x7479e3384c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x7479e2d649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x7479e29b3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x747a04602052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x747a04600925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x747a0460106e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x747a04612c88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x747a04611c44]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:48] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 46) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x7b92e5ea6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x7b92e6784c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x7b92e61649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x7b92e5db3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x7b93075d9052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x7b93075d7925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7b93075d806e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x7b93075e9c88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x7b93075e8c44]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1222, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1678, in _init\n",
      "    it.reraise()\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 572, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 553, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1654, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 629, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 961, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 1099, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1603, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 713, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/data.py\", line 1533, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:46:49] /workspace/src/data/array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "Stack trace:\n",
      "  [bt] (0) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6acc) [0x7e3abfca6acc]\n",
      "  [bt] (1) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xb84c1c) [0x7e3ac0584c1c]\n",
      "  [bt] (2) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5649ce) [0x7e3abff649ce]\n",
      "  [bt] (3) /home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0x10b) [0x7e3abfbb3a5b]\n",
      "  [bt] (4) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x7e3ae17ab052]\n",
      "  [bt] (5) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x7e3ae17a9925]\n",
      "  [bt] (6) /home/21827840/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7e3ae17aa06e]\n",
      "  [bt] (7) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x9c88) [0x7e3ae17bbc88]\n",
      "  [bt] (8) /home/21827840/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x8c44) [0x7e3ae17bac44]\n",
      "\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan -0.01470175         nan\n",
      "         nan         nan -0.00604694 -0.00617958 -0.00472864 -0.00488889\n",
      " -0.00374452 -0.00376261 -0.00303618 -0.0031136  -0.0183448  -0.01840603\n",
      " -0.01364632 -0.01381142 -0.01450479 -0.01466298 -0.00922596 -0.00944126\n",
      " -0.00601872 -0.00615143 -0.00470007 -0.00489488 -0.00363596 -0.00376688\n",
      " -0.00295209 -0.00313622]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     41\u001b[39m     pred = best_model.predict(X_val)\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model, mean_squared_error(y_val, pred), r2_score(y_val, pred)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43mtrain_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain_xgboost\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m model = xgb.XGBRegressor(objective=\u001b[33m\"\u001b[39m\u001b[33mreg:squarederror\u001b[39m\u001b[33m\"\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     15\u001b[39m grid_search = GridSearchCV(model, param_grid=param_grid, cv=\u001b[32m3\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33mneg_mean_squared_error\u001b[39m\u001b[33m'\u001b[39m, verbose=\u001b[32m1\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m best_model = grid_search.best_estimator_\n\u001b[32m     19\u001b[39m pred = best_model.predict(X_val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1062\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1060\u001b[39m refit_start_time = time.time()\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_estimator_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28mself\u001b[39m.best_estimator_.fit(X, **routed_params.estimator.fit)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/sklearn.py:1247\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/xgboost/core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_xgboost():\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    pred = best_model.predict(X_val)\n",
    "    return best_model, mean_squared_error(y_val, pred), r2_score(y_val, pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def train_svr():\n",
    "    param_grid = {\n",
    "        'svr__C': [1, 10, 100],\n",
    "        'svr__epsilon': [0.01, 0.1,0.5],\n",
    "        'svr__kernel': ['rbf']\n",
    "    }\n",
    "\n",
    "    pipeline = make_pipeline( SVR())\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    pred = best_model.predict(X_val)\n",
    "    return best_model, mean_squared_error(y_val, pred), r2_score(y_val, pred)\n",
    "\n",
    "\n",
    "\n",
    "train_xgboost()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61441d75",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m svrModel,mse,r2 = _\n\u001b[32m      3\u001b[39m svrModel.kernel\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0fe7d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'kernel'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msvrModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkernel\u001b[49m\n\u001b[32m      2\u001b[39m mse\n\u001b[32m      3\u001b[39m r2\n",
      "\u001b[31mAttributeError\u001b[39m: 'Pipeline' object has no attribute 'kernel'"
     ]
    }
   ],
   "source": [
    "svrModel.\n",
    "mse\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb7afafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/21827840/uni/ML/assignment/tf/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0331 - mae: 0.1104 - val_loss: 0.0118 - val_mae: 0.0554\n",
      "Epoch 2/500\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0565 - val_loss: 0.0104 - val_mae: 0.0501\n",
      "Epoch 3/500\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0101 - mae: 0.0504 - val_loss: 0.0095 - val_mae: 0.0478\n",
      "Epoch 4/500\n",
      "\u001b[1m  1/222\u001b[0m \u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0075 - mae: 0.0398"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     27\u001b[39m     history = model.fit(\n\u001b[32m     28\u001b[39m     X_train, y_train,\n\u001b[32m     29\u001b[39m     validation_data=(X_val, y_val),\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m )\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mbuild_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mbuild_nn\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[32m     24\u001b[39m     early_stop = callbacks.EarlyStopping(\n\u001b[32m     25\u001b[39m         monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m100\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     26\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    130\u001b[39m args = args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[32m    131\u001b[39m kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m function = \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:205\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_define_function\u001b[39m(args, kwargs, tracing_options):\n\u001b[32m    189\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Gets a function for these inputs, defining it if necessary.\u001b[39;00m\n\u001b[32m    190\u001b[39m \n\u001b[32m    191\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    203\u001b[39m \u001b[33;03m      shape relaxation retracing.\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m   bound_args = \u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanonicalize_function_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpolymorphic_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_pure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m   args, kwargs = bound_args.args, bound_args.kwargs\n\u001b[32m    214\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m tracing_options.input_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:422\u001b[39m, in \u001b[36mcanonicalize_function_inputs\u001b[39m\u001b[34m(args, kwargs, function_type, default_values, is_pure)\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_pure:\n\u001b[32m    421\u001b[39m   args, kwargs = _convert_variables_to_tensors(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m bound_arguments = \u001b[43mbind_function_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_values\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m bound_arguments\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:442\u001b[39m, in \u001b[36mbind_function_inputs\u001b[39m\u001b[34m(args, kwargs, function_type, default_values)\u001b[39m\n\u001b[32m    434\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    435\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mName collision after sanitization. Please rename \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    436\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mtf.function input parameters. Original: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    437\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Sanitized: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    438\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(sanitized_kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    439\u001b[39m   )\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m   bound_arguments = \u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_with_defaults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_values\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    446\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    447\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBinding inputs to tf.function failed due to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    448\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msanitized_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for signature:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    449\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m   ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:264\u001b[39m, in \u001b[36mFunctionType.bind_with_defaults\u001b[39m\u001b[34m(self, args, kwargs, default_values)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind_with_defaults\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, kwargs, default_values):\n\u001b[32m    263\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Returns BoundArguments with default values filled in.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m   bound_arguments = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m   bound_arguments.apply_defaults()\n\u001b[32m    267\u001b[39m   with_default_args = collections.OrderedDict()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/inspect.py:3277\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3273\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3274\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3275\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3276\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/inspect.py:3270\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3265\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3266\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3267\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3268\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m-> \u001b[39m\u001b[32m3270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_arguments_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/inspect.py:2888\u001b[39m, in \u001b[36mBoundArguments.__init__\u001b[39m\u001b[34m(self, signature, arguments)\u001b[39m\n\u001b[32m   2870\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Result of `Signature.bind` call.  Holds the mapping of arguments\u001b[39;00m\n\u001b[32m   2871\u001b[39m \u001b[33;03mto the function's parameters.\u001b[39;00m\n\u001b[32m   2872\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2883\u001b[39m \u001b[33;03m    Dict of keyword arguments values.\u001b[39;00m\n\u001b[32m   2884\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2886\u001b[39m \u001b[34m__slots__\u001b[39m = (\u001b[33m'\u001b[39m\u001b[33marguments\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_signature\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m__weakref__\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2888\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, signature, arguments):\n\u001b[32m   2889\u001b[39m     \u001b[38;5;28mself\u001b[39m.arguments = arguments\n\u001b[32m   2890\u001b[39m     \u001b[38;5;28mself\u001b[39m._signature = signature\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mish(x):\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "\n",
    "def build_nn():\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(256, activation='mish', input_shape=(X_train.shape[1],),\n",
    "                    kernel_regularizer=regularizers.l2(1e-5)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(256, activation='mish', kernel_regularizer=regularizers.l2(1e-5)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(256, activation='mish', kernel_regularizer=regularizers.l2(1e-5)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(1, activation='softplus')\n",
    "    ])\n",
    "\n",
    "    optimizer = optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    # Callbacks\n",
    "    early_stop = callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=100, restore_best_weights=True\n",
    "    )\n",
    "    history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    "    \n",
    ")\n",
    "    return model\n",
    "\n",
    "build_nn()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fbe2806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1006 - mae: 0.0965\n",
      "Validation Loss: 0.09531672298908234\n",
      "Validation MAE: 0.09574490785598755\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = load_model('best.keras')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on the validation dataset only\n",
    "val_loss, val_mae = model.evaluate(X_val, y_val, batch_size=512, verbose=1)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation MAE: {val_mae}\")\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     epochs=2000,\n",
    "#     batch_size=512,\n",
    "#     callbacks=[early_stop],\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36878c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75fdbe5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m      2\u001b[39m plt.subplot(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m plt.plot(\u001b[43mhistory\u001b[49m.history[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mTraining Loss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m plt.plot(history.history[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mValidation Loss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mTraining & Validation Loss\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training & Validation MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Training & Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3700ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 14:17:28.905339: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-05-04 14:17:28.942106: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-05-04 14:17:28.993606: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2025-05-04 14:17:29.652308: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2025-05-04 14:17:29.698716: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.3073 - mae: 0.7240\n",
      "Epoch 1: val_loss improved from inf to 0.08407, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - loss: 2.3008 - mae: 0.7226 - val_loss: 0.0841 - val_mae: 0.1886 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m218/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1520 - mae: 0.2453\n",
      "Epoch 2: val_loss did not improve from 0.08407\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1515 - mae: 0.2451 - val_loss: 0.1045 - val_mae: 0.2278 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m215/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1121 - mae: 0.2325\n",
      "Epoch 3: val_loss did not improve from 0.08407\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1120 - mae: 0.2324 - val_loss: 0.1053 - val_mae: 0.2280 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1118 - mae: 0.2326\n",
      "Epoch 4: val_loss did not improve from 0.08407\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1117 - mae: 0.2325 - val_loss: 0.1014 - val_mae: 0.2268 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m219/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1016 - mae: 0.2223\n",
      "Epoch 5: val_loss did not improve from 0.08407\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1016 - mae: 0.2223 - val_loss: 0.0989 - val_mae: 0.2247 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1005 - mae: 0.2218\n",
      "Epoch 6: val_loss did not improve from 0.08407\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1005 - mae: 0.2218 - val_loss: 0.0937 - val_mae: 0.2160 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1053 - mae: 0.2242\n",
      "Epoch 7: val_loss did not improve from 0.08407\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1053 - mae: 0.2242 - val_loss: 0.0951 - val_mae: 0.2171 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0997 - mae: 0.2198\n",
      "Epoch 8: val_loss did not improve from 0.08407\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0997 - mae: 0.2198 - val_loss: 0.0872 - val_mae: 0.2067 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m218/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1035 - mae: 0.2227\n",
      "Epoch 9: val_loss did not improve from 0.08407\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1036 - mae: 0.2227 - val_loss: 0.0903 - val_mae: 0.2119 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m218/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1037 - mae: 0.2212\n",
      "Epoch 10: val_loss did not improve from 0.08407\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1037 - mae: 0.2212 - val_loss: 0.0847 - val_mae: 0.2049 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m215/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0985 - mae: 0.2148\n",
      "Epoch 11: val_loss did not improve from 0.08407\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0985 - mae: 0.2149 - val_loss: 0.0858 - val_mae: 0.2047 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1010 - mae: 0.2216\n",
      "Epoch 12: val_loss improved from 0.08407 to 0.08350, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1010 - mae: 0.2216 - val_loss: 0.0835 - val_mae: 0.2033 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0942 - mae: 0.2092\n",
      "Epoch 13: val_loss did not improve from 0.08350\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0942 - mae: 0.2093 - val_loss: 0.0857 - val_mae: 0.2042 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0942 - mae: 0.2124\n",
      "Epoch 14: val_loss did not improve from 0.08350\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0942 - mae: 0.2124 - val_loss: 0.0852 - val_mae: 0.2045 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0923 - mae: 0.2087\n",
      "Epoch 15: val_loss improved from 0.08350 to 0.07157, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0923 - mae: 0.2086 - val_loss: 0.0716 - val_mae: 0.1813 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m218/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0878 - mae: 0.1991\n",
      "Epoch 16: val_loss improved from 0.07157 to 0.06237, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0877 - mae: 0.1990 - val_loss: 0.0624 - val_mae: 0.1674 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m213/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0850 - mae: 0.1935\n",
      "Epoch 17: val_loss improved from 0.06237 to 0.05993, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0851 - mae: 0.1935 - val_loss: 0.0599 - val_mae: 0.1581 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m218/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0851 - mae: 0.1945\n",
      "Epoch 18: val_loss improved from 0.05993 to 0.04501, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0850 - mae: 0.1943 - val_loss: 0.0450 - val_mae: 0.1325 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0797 - mae: 0.1802\n",
      "Epoch 19: val_loss did not improve from 0.04501\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0797 - mae: 0.1802 - val_loss: 0.0610 - val_mae: 0.1596 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m214/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0719 - mae: 0.1716\n",
      "Epoch 20: val_loss did not improve from 0.04501\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0719 - mae: 0.1715 - val_loss: 0.0469 - val_mae: 0.1305 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m211/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0683 - mae: 0.1655\n",
      "Epoch 21: val_loss improved from 0.04501 to 0.03921, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0683 - mae: 0.1655 - val_loss: 0.0392 - val_mae: 0.1135 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m219/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0653 - mae: 0.1602\n",
      "Epoch 22: val_loss improved from 0.03921 to 0.03911, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0652 - mae: 0.1601 - val_loss: 0.0391 - val_mae: 0.1127 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0607 - mae: 0.1509\n",
      "Epoch 23: val_loss improved from 0.03911 to 0.03543, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0607 - mae: 0.1509 - val_loss: 0.0354 - val_mae: 0.0993 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m215/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0565 - mae: 0.1441\n",
      "Epoch 24: val_loss improved from 0.03543 to 0.02964, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0565 - mae: 0.1441 - val_loss: 0.0296 - val_mae: 0.0857 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.1462\n",
      "Epoch 25: val_loss improved from 0.02964 to 0.02928, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0585 - mae: 0.1462 - val_loss: 0.0293 - val_mae: 0.0850 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0528 - mae: 0.1371\n",
      "Epoch 26: val_loss improved from 0.02928 to 0.02598, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0528 - mae: 0.1371 - val_loss: 0.0260 - val_mae: 0.0738 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0496 - mae: 0.1284\n",
      "Epoch 27: val_loss did not improve from 0.02598\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0496 - mae: 0.1284 - val_loss: 0.0315 - val_mae: 0.0865 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m219/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0488 - mae: 0.1292\n",
      "Epoch 28: val_loss improved from 0.02598 to 0.02515, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0488 - mae: 0.1292 - val_loss: 0.0251 - val_mae: 0.0674 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m216/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0446 - mae: 0.1190\n",
      "Epoch 29: val_loss improved from 0.02515 to 0.02510, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0446 - mae: 0.1189 - val_loss: 0.0251 - val_mae: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m214/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0444 - mae: 0.1181\n",
      "Epoch 30: val_loss improved from 0.02510 to 0.02482, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0444 - mae: 0.1181 - val_loss: 0.0248 - val_mae: 0.0653 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m216/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0434 - mae: 0.1150\n",
      "Epoch 31: val_loss improved from 0.02482 to 0.02421, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0434 - mae: 0.1149 - val_loss: 0.0242 - val_mae: 0.0637 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m218/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0403 - mae: 0.1094\n",
      "Epoch 32: val_loss improved from 0.02421 to 0.02352, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0403 - mae: 0.1094 - val_loss: 0.0235 - val_mae: 0.0605 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0388 - mae: 0.1054\n",
      "Epoch 33: val_loss improved from 0.02352 to 0.02338, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0388 - mae: 0.1054 - val_loss: 0.0234 - val_mae: 0.0595 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0371 - mae: 0.1021\n",
      "Epoch 34: val_loss improved from 0.02338 to 0.02329, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0371 - mae: 0.1021 - val_loss: 0.0233 - val_mae: 0.0586 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m218/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0372 - mae: 0.1005\n",
      "Epoch 35: val_loss improved from 0.02329 to 0.02300, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0372 - mae: 0.1005 - val_loss: 0.0230 - val_mae: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m214/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0345 - mae: 0.0946\n",
      "Epoch 36: val_loss improved from 0.02300 to 0.02269, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0346 - mae: 0.0947 - val_loss: 0.0227 - val_mae: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m215/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0345 - mae: 0.0957\n",
      "Epoch 37: val_loss improved from 0.02269 to 0.02266, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0346 - mae: 0.0957 - val_loss: 0.0227 - val_mae: 0.0551 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m216/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.0948\n",
      "Epoch 38: val_loss improved from 0.02266 to 0.02243, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.0948 - val_loss: 0.0224 - val_mae: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m216/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.0941\n",
      "Epoch 39: val_loss improved from 0.02243 to 0.02234, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.0940 - val_loss: 0.0223 - val_mae: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0325 - mae: 0.0899\n",
      "Epoch 40: val_loss improved from 0.02234 to 0.02226, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0325 - mae: 0.0899 - val_loss: 0.0223 - val_mae: 0.0543 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m218/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0331 - mae: 0.0910\n",
      "Epoch 41: val_loss improved from 0.02226 to 0.02200, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0331 - mae: 0.0910 - val_loss: 0.0220 - val_mae: 0.0531 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0317 - mae: 0.0870\n",
      "Epoch 42: val_loss improved from 0.02200 to 0.02189, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0317 - mae: 0.0870 - val_loss: 0.0219 - val_mae: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m218/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0313 - mae: 0.0861\n",
      "Epoch 43: val_loss did not improve from 0.02189\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0313 - mae: 0.0861 - val_loss: 0.0219 - val_mae: 0.0524 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0307 - mae: 0.0850\n",
      "Epoch 44: val_loss did not improve from 0.02189\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0307 - mae: 0.0850 - val_loss: 0.0222 - val_mae: 0.0541 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m210/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0310 - mae: 0.0857\n",
      "Epoch 45: val_loss did not improve from 0.02189\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0310 - mae: 0.0855 - val_loss: 0.0220 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0297 - mae: 0.0820\n",
      "Epoch 46: val_loss did not improve from 0.02189\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0297 - mae: 0.0820 - val_loss: 0.0223 - val_mae: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0295 - mae: 0.0816\n",
      "Epoch 47: val_loss did not improve from 0.02189\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0295 - mae: 0.0816 - val_loss: 0.0220 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0288 - mae: 0.0793\n",
      "Epoch 48: val_loss improved from 0.02189 to 0.02168, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0288 - mae: 0.0793 - val_loss: 0.0217 - val_mae: 0.0516 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0284 - mae: 0.0776\n",
      "Epoch 49: val_loss did not improve from 0.02168\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0284 - mae: 0.0776 - val_loss: 0.0221 - val_mae: 0.0533 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0281 - mae: 0.0778\n",
      "Epoch 50: val_loss improved from 0.02168 to 0.02163, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0281 - mae: 0.0778 - val_loss: 0.0216 - val_mae: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0280 - mae: 0.0770\n",
      "Epoch 51: val_loss improved from 0.02163 to 0.02157, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0280 - mae: 0.0770 - val_loss: 0.0216 - val_mae: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0279 - mae: 0.0767\n",
      "Epoch 52: val_loss did not improve from 0.02157\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0279 - mae: 0.0767 - val_loss: 0.0218 - val_mae: 0.0520 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m216/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0272 - mae: 0.0753\n",
      "Epoch 53: val_loss did not improve from 0.02157\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0272 - mae: 0.0753 - val_loss: 0.0217 - val_mae: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m218/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0279 - mae: 0.0760\n",
      "Epoch 54: val_loss did not improve from 0.02157\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0279 - mae: 0.0760 - val_loss: 0.0219 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m219/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.0730\n",
      "Epoch 55: val_loss improved from 0.02157 to 0.02154, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0266 - mae: 0.0731 - val_loss: 0.0215 - val_mae: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m214/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0277 - mae: 0.0765\n",
      "Epoch 56: val_loss improved from 0.02154 to 0.02144, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0277 - mae: 0.0764 - val_loss: 0.0214 - val_mae: 0.0506 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0268 - mae: 0.0732\n",
      "Epoch 57: val_loss did not improve from 0.02144\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0268 - mae: 0.0732 - val_loss: 0.0218 - val_mae: 0.0531 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m208/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0270 - mae: 0.0737\n",
      "Epoch 58: val_loss did not improve from 0.02144\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0270 - mae: 0.0737 - val_loss: 0.0215 - val_mae: 0.0518 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m216/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0263 - mae: 0.0717\n",
      "Epoch 59: val_loss improved from 0.02144 to 0.02135, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0263 - mae: 0.0717 - val_loss: 0.0214 - val_mae: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0261 - mae: 0.0716\n",
      "Epoch 60: val_loss did not improve from 0.02135\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0261 - mae: 0.0717 - val_loss: 0.0214 - val_mae: 0.0516 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m213/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0262 - mae: 0.0714\n",
      "Epoch 61: val_loss improved from 0.02135 to 0.02125, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0262 - mae: 0.0714 - val_loss: 0.0213 - val_mae: 0.0504 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m213/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0264 - mae: 0.0719\n",
      "Epoch 62: val_loss did not improve from 0.02125\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0264 - mae: 0.0718 - val_loss: 0.0214 - val_mae: 0.0514 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0263 - mae: 0.0721\n",
      "Epoch 63: val_loss did not improve from 0.02125\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0263 - mae: 0.0720 - val_loss: 0.0218 - val_mae: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - mae: 0.0701\n",
      "Epoch 64: val_loss did not improve from 0.02125\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0259 - mae: 0.0701 - val_loss: 0.0213 - val_mae: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0254 - mae: 0.0685\n",
      "Epoch 65: val_loss did not improve from 0.02125\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0254 - mae: 0.0685 - val_loss: 0.0214 - val_mae: 0.0514 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m219/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0259 - mae: 0.0699\n",
      "Epoch 66: val_loss did not improve from 0.02125\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0259 - mae: 0.0699 - val_loss: 0.0216 - val_mae: 0.0520 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0253 - mae: 0.0680\n",
      "Epoch 67: val_loss did not improve from 0.02125\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0254 - mae: 0.0680 - val_loss: 0.0219 - val_mae: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0262 - mae: 0.0712\n",
      "Epoch 68: val_loss did not improve from 0.02125\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0262 - mae: 0.0712 - val_loss: 0.0214 - val_mae: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m219/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0254 - mae: 0.0685\n",
      "Epoch 69: val_loss did not improve from 0.02125\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0254 - mae: 0.0685 - val_loss: 0.0215 - val_mae: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0257 - mae: 0.0693\n",
      "Epoch 70: val_loss did not improve from 0.02125\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0256 - mae: 0.0693 - val_loss: 0.0214 - val_mae: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m219/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0250 - mae: 0.0670\n",
      "Epoch 71: val_loss did not improve from 0.02125\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0250 - mae: 0.0670 - val_loss: 0.0214 - val_mae: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m210/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0250 - mae: 0.0675\n",
      "Epoch 72: val_loss did not improve from 0.02125\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0250 - mae: 0.0675 - val_loss: 0.0216 - val_mae: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m216/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0249 - mae: 0.0672\n",
      "Epoch 73: val_loss improved from 0.02125 to 0.02121, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - mae: 0.0672 - val_loss: 0.0212 - val_mae: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0252 - mae: 0.0677\n",
      "Epoch 74: val_loss improved from 0.02121 to 0.02115, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0252 - mae: 0.0677 - val_loss: 0.0211 - val_mae: 0.0502 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0246 - mae: 0.0662\n",
      "Epoch 75: val_loss did not improve from 0.02115\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0246 - mae: 0.0662 - val_loss: 0.0215 - val_mae: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m218/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0251 - mae: 0.0674\n",
      "Epoch 76: val_loss improved from 0.02115 to 0.02109, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0251 - mae: 0.0674 - val_loss: 0.0211 - val_mae: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0244 - mae: 0.0654\n",
      "Epoch 77: val_loss did not improve from 0.02109\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0244 - mae: 0.0654 - val_loss: 0.0212 - val_mae: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m215/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0248 - mae: 0.0659\n",
      "Epoch 78: val_loss improved from 0.02109 to 0.02106, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0248 - mae: 0.0659 - val_loss: 0.0211 - val_mae: 0.0499 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m219/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - mae: 0.0656\n",
      "Epoch 79: val_loss did not improve from 0.02106\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0245 - mae: 0.0656 - val_loss: 0.0212 - val_mae: 0.0505 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0241 - mae: 0.0643\n",
      "Epoch 80: val_loss improved from 0.02106 to 0.02082, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0241 - mae: 0.0643 - val_loss: 0.0208 - val_mae: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m221/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0239 - mae: 0.0643\n",
      "Epoch 81: val_loss did not improve from 0.02082\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0239 - mae: 0.0643 - val_loss: 0.0209 - val_mae: 0.0495 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m215/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0244 - mae: 0.0661\n",
      "Epoch 82: val_loss improved from 0.02082 to 0.02074, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0244 - mae: 0.0660 - val_loss: 0.0207 - val_mae: 0.0486 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m219/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0236 - mae: 0.0630\n",
      "Epoch 83: val_loss did not improve from 0.02074\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0236 - mae: 0.0630 - val_loss: 0.0209 - val_mae: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0239 - mae: 0.0631\n",
      "Epoch 84: val_loss did not improve from 0.02074\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0239 - mae: 0.0631 - val_loss: 0.0208 - val_mae: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0237 - mae: 0.0628\n",
      "Epoch 85: val_loss improved from 0.02074 to 0.02070, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0237 - mae: 0.0628 - val_loss: 0.0207 - val_mae: 0.0483 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m216/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0236 - mae: 0.0623\n",
      "Epoch 86: val_loss did not improve from 0.02070\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0236 - mae: 0.0623 - val_loss: 0.0209 - val_mae: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m220/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0246 - mae: 0.0647\n",
      "Epoch 87: val_loss did not improve from 0.02070\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0246 - mae: 0.0647 - val_loss: 0.0207 - val_mae: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m214/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0243 - mae: 0.0651\n",
      "Epoch 88: val_loss improved from 0.02070 to 0.02066, saving model to best_bleve_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0243 - mae: 0.0650 - val_loss: 0.0207 - val_mae: 0.0483 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m215/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0248 - mae: 0.0665\n",
      "Epoch 89: val_loss did not improve from 0.02066\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0248 - mae: 0.0664 - val_loss: 0.0208 - val_mae: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0239 - mae: 0.0638\n",
      "Epoch 90: val_loss did not improve from 0.02066\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0239 - mae: 0.0638 - val_loss: 0.0209 - val_mae: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m217/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0234 - mae: 0.0612\n",
      "Epoch 91: val_loss did not improve from 0.02066\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0234 - mae: 0.0613 - val_loss: 0.0208 - val_mae: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m 30/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0240 - mae: 0.0652"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[32m     79\u001b[39m     history = model.fit(\n\u001b[32m     80\u001b[39m         X_train, y_train,\n\u001b[32m     81\u001b[39m         validation_data=(X_val, y_val),\n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m         verbose=\u001b[32m1\u001b[39m\n\u001b[32m     86\u001b[39m     )\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuild_advanced_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, batch_size, epochs)\u001b[39m\n\u001b[32m     71\u001b[39m checkpoint = callbacks.ModelCheckpoint(\n\u001b[32m     72\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbest_bleve_model.h5\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     73\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     74\u001b[39m     save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     75\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     76\u001b[39m )\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Train with callbacks\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     86\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m     iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m ):\n\u001b[32m    219\u001b[39m     opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[39m, in \u001b[36m_OptionalImpl.has_value\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[39m, in \u001b[36moptional_has_value\u001b[39m\u001b[34m(optional, name)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m    171\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOptionalHasValue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input , Dense\n",
    "\n",
    "def build_residual_block(x, units, dropout_rate=0.2):\n",
    "    \"\"\"Build a residual block with skip connections\"\"\"\n",
    "    # Store the input for the skip connection\n",
    "    skip = x\n",
    "    \n",
    "    # Main path\n",
    "    x = Dense(units, activation=mish, kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(units, activation=mish, kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Add skip connection if dimensions match, otherwise project\n",
    "    if skip.shape[-1] != units:\n",
    "        skip = Dense(units, kernel_regularizer=regularizers.l2(1e-5))(skip)\n",
    "    \n",
    "    # Add skip connection\n",
    "    x = Add()([x, skip])\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_advanced_nn(input_shape, learning_rate=0.001):\n",
    "    \"\"\"Build an advanced neural network with residual connections\"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    \n",
    "    # Initial dense layer\n",
    "    x = Dense(128, activation=mish, kernel_regularizer=regularizers.l2(1e-5))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Residual blocks\n",
    "    x = build_residual_block(x, 256, dropout_rate=0.2)\n",
    "    x = build_residual_block(x, 256, dropout_rate=0.2)\n",
    "    x = build_residual_block(x, 128, dropout_rate=0.2)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='softplus')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile with AMSGrad variant of Adam optimizer (more stable than standard Adam)\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate, amsgrad=True)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, batch_size=32, epochs=1000):\n",
    "    \"\"\"Train model with advanced scheduling and callbacks\"\"\"\n",
    "    # Learning rate scheduler\n",
    "    lr_scheduler = callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=30,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stop = callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=100,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Model checkpoint\n",
    "    checkpoint = callbacks.ModelCheckpoint(\n",
    "        'best_bleve_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train with callbacks\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stop, lr_scheduler, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "train_model(build_advanced_nn(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd6b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tank Failure Pressure  Liquid Ratio  Tank Width  Tank Length  Tank Height  \\\n",
      "0                   37.9      0.412227         0.8          6.6          0.4   \n",
      "\n",
      "   BLEVE Height  Vapour Height  Vapour Temperature  Liquid Temperature  \\\n",
      "0           0.8            0.2               317.6               337.5   \n",
      "\n",
      "   Obstacle Distance to BLEVE  Obstacle Width  Obstacle Height  \\\n",
      "0                           7               9               12   \n",
      "\n",
      "   Obstacle Thickness  Obstacle Angle  Liquid Critical Pressure  \\\n",
      "0                 0.6               0                      42.5   \n",
      "\n",
      "   Liquid Boiling Temperature  Liquid Critical Temperature  Sensor ID  \\\n",
      "0                      231.15                       369.85          1   \n",
      "\n",
      "   Sensor Position x  Sensor Position y  Sensor Position z  Tank Volume  \\\n",
      "0               8.05               -4.3               -0.7        2.112   \n",
      "\n",
      "   HeightRatio  Superheat Margin  Side_1  Side_2  Side_3  Side_4  Side_5  \\\n",
      "0          0.5            106.35    True   False   False   False   False   \n",
      "\n",
      "   Status_subcooled  Status_superheated  \n",
      "0              True               False  \n",
      "\u001b[1m101/101\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.2141 - mae: 0.3790\n",
      "Test Loss: 0.20895014703273773\n",
      "Test MAE: 0.3721587657928467\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step\n",
      "MAPE: 0.24436831921410368\n",
      "Predictions have been saved to 'predictions_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have X_test and y_test prepared\n",
    "# 1. Evaluate the model on the test set\n",
    "test_data =   pd.read_csv(\"test.csv\")\n",
    "y_test = pd.read_csv(\"sample_prediction.csv\")\n",
    "predData = y_test[\"Target Pressure (bar)\"]\n",
    "test_scaled,_ = preprocess(test_data,True)\n",
    "test_loss, test_mae = model.evaluate(test_scaled, predData)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "\n",
    "\n",
    "y_pred = model.predict(test_scaled).flatten()  # Ensure it's a 1D array\n",
    "\n",
    "# 2. Get the true target values\n",
    "y_true = y_test[\"Target Pressure (bar)\"].values\n",
    "\n",
    "\n",
    "\n",
    "# 3. Calculate MAPE (excluding zero targets to avoid division by zero)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
    "\n",
    "# 4. Compute and print MAPE\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "print(f\"MAPE: {mape/10}\")\n",
    "\n",
    "\n",
    "# Assuming the ID column in the test data is named 'ID'\n",
    "# 1. Create a DataFrame with the predictions and IDs\n",
    "output_df = pd.DataFrame({\n",
    "    'ID': y_test['ID'],  # Assuming 'ID' is in the test_data\n",
    "    'Target Pressure (bar)': y_pred  # The predicted values\n",
    "})\n",
    "\n",
    "# 2. Save the DataFrame to a CSV file\n",
    "output_df.to_csv('predictions_output.csv', index=False)\n",
    "print(\"Predictions have been saved to 'predictions_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aadd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuner_dir/mish_model/tuner0.json\n",
      "\n",
      "Search: Running Trial #14\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "4                 |2                 |num_layers\n",
      "320               |192               |units_0\n",
      "0.001             |0.0001            |l2_reg\n",
      "0.5               |0.1               |dropout_0\n",
      "320               |512               |units_1\n",
      "0.4               |0.4               |dropout_1\n",
      "0.01              |0.1               |learning_rate\n",
      "0.7               |0.7               |momentum\n",
      "384               |128               |units_2\n",
      "0.2               |0.1               |dropout_2\n",
      "512               |128               |units_3\n",
      "0.2               |0.1               |dropout_3\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 1.2419 - mae: 0.2426 - val_loss: 1.1589 - val_mae: 0.1386\n",
      "Epoch 2/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1487 - mae: 0.1238 - val_loss: 1.1178 - val_mae: 0.1137\n",
      "Epoch 3/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1094 - mae: 0.1038 - val_loss: 1.0812 - val_mae: 0.0954\n",
      "Epoch 4/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0750 - mae: 0.0929 - val_loss: 1.0478 - val_mae: 0.0835\n",
      "Epoch 5/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0425 - mae: 0.0838 - val_loss: 1.0165 - val_mae: 0.0766\n",
      "Epoch 6/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0114 - mae: 0.0790 - val_loss: 0.9867 - val_mae: 0.0734\n",
      "Epoch 7/100\n",
      "\u001b[1m190/222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9832 - mae: 0.0779"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m tf.keras.utils.get_custom_objects().update({\u001b[33m'\u001b[39m\u001b[33mmish\u001b[39m\u001b[33m'\u001b[39m: mish})\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Run search\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_loss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     48\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m best_model = tuner.get_best_models(num_models=\u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m     52\u001b[39m best_hps = tuner.get_best_hyperparameters(\u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[39m, in \u001b[36mBaseTuner.search\u001b[39m\u001b[34m(self, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_begin(trial)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_end(trial)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.on_search_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[39m, in \u001b[36mBaseTuner._try_run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m         trial.status = trial_module.TrialStatus.COMPLETED\n\u001b[32m    276\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[39m, in \u001b[36mBaseTuner._run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[32m    241\u001b[39m         \u001b[38;5;28mself\u001b[39m.oracle.objective.name\n\u001b[32m    242\u001b[39m     ):\n\u001b[32m    243\u001b[39m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[32m    244\u001b[39m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[32m    245\u001b[39m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[32m    246\u001b[39m         warnings.warn(\n\u001b[32m    247\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe use case of calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    254\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    255\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[39m, in \u001b[36mTuner.run_trial\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    312\u001b[39m     callbacks.append(model_checkpoint)\n\u001b[32m    313\u001b[39m     copied_kwargs[\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m] = callbacks\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     obj_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m     histories.append(obj_value)\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[39m, in \u001b[36mTuner._build_and_fit_model\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m hp = trial.hyperparameters\n\u001b[32m    232\u001b[39m model = \u001b[38;5;28mself\u001b[39m._try_build(hp)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.config.multi_backend():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[39m, in \u001b[36mHyperModel.fit\u001b[39m\u001b[34m(self, hp, model, *args, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, *args, **kwargs):\n\u001b[32m    126\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[32m    127\u001b[39m \n\u001b[32m    128\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m \u001b[33;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    130\u001b[39m args = args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[32m    131\u001b[39m kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m function = \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:239\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    229\u001b[39m lookup_func_type, lookup_func_context = (\n\u001b[32m    230\u001b[39m     function_type_utils.make_canonicalized_monomorphic_type(\n\u001b[32m    231\u001b[39m         args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    235\u001b[39m     )\n\u001b[32m    236\u001b[39m )\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m   concrete_function = \u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunction_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m      \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    243\u001b[39m   concrete_function = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_cache.py:48\u001b[39m, in \u001b[36mFunctionCache.lookup\u001b[39m\u001b[34m(self, function_type, context)\u001b[39m\n\u001b[32m     46\u001b[39m context = context \u001b[38;5;129;01mor\u001b[39;00m FunctionContext()\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dispatch_dict:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m   dispatch_type = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._primary[(context, dispatch_type)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/type_dispatch.py:85\u001b[39m, in \u001b[36mTypeDispatchTable.dispatch\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     81\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m request\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# For known non-exact matches.\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# (self._dispatch cache does not contain exact matches)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_cache\u001b[49m:\n\u001b[32m     86\u001b[39m   \u001b[38;5;66;03m# Move to the front of LRU cache.\u001b[39;00m\n\u001b[32m     87\u001b[39m   result = \u001b[38;5;28mself\u001b[39m._dispatch_cache.pop(request)\n\u001b[32m     88\u001b[39m   \u001b[38;5;28mself\u001b[39m._dispatch_cache[request] = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:456\u001b[39m, in \u001b[36mFunctionType.__eq__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, FunctionType):\n\u001b[32m    454\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m, \u001b[38;5;28mself\u001b[39m.captures) == (other.parameters,\n\u001b[32m    457\u001b[39m                                             other.captures)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni/ML/assignment/tf/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:198\u001b[39m, in \u001b[36mFunctionType.parameters\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    197\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Returns an ordered mapping of parameter name to specification.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/inspect.py:3089\u001b[39m, in \u001b[36mSignature.parameters\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3084\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[32m   3085\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_callable(obj, sigcls=\u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   3086\u001b[39m                                     follow_wrapper_chains=follow_wrapped,\n\u001b[32m   3087\u001b[39m                                     \u001b[38;5;28mglobals\u001b[39m=\u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m=\u001b[38;5;28mlocals\u001b[39m, eval_str=eval_str)\n\u001b[32m-> \u001b[39m\u001b[32m3089\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   3090\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparameters\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   3091\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parameters\n\u001b[32m   3093\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   3094\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreturn_annotation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Tunable units\n",
    "    for i in range(hp.Int(\"num_layers\", 2, 4)):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=128, max_value=512, step=64),\n",
    "            activation='mish',\n",
    "            kernel_regularizer=regularizers.l2(hp.Choice('l2_reg', [1e-5, 1e-4, 1e-3]))\n",
    "        ))\n",
    "        model.add(layers.Dropout(rate=hp.Float(f'dropout_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='softplus'))\n",
    "    \n",
    "    # Compile\n",
    "    optimizer = optimizers.SGD(\n",
    "        learning_rate=hp.Choice('learning_rate', [0.01, 0.05, 0.1]),\n",
    "        momentum=hp.Float('momentum', min_value=0.5, max_value=0.95, step=0.05)\n",
    "    )\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='mish_model'\n",
    ")\n",
    "\n",
    "# Register Mish\n",
    "tf.keras.utils.get_custom_objects().update({'mish': mish})\n",
    "\n",
    "# Run search\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=10)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for key in best_hps.values:\n",
    "    print(f\"{key}: {best_hps.get(key)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
